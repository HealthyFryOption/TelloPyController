AFollowingo the current NeuralNet_DEEP CNN architecture, its DRONE_LABELS classes, and makeTrainingData.ipynb, please add a folder named 'handCapture' in this directory that subsequently contains 6 folders with the names of the gestures:

1) openPalm
2) fist
3) peace
4) right 
5) left 
6) thumbsUp

a) Use testModelTrack.py to connects to a webcam and Through hand tracking, by pressing 'c', take custom pictures of a gesture. View that file for more info. 
   NOTE: YOU CAN SKIP a) IF YOU ALREADY HAVE A DATASET READY

b) After collecting enough dataset images, run makeTrainingData.ipynb to create a .npy file containing the data of all images.
c) Run makeModel.ipynb to train model and save your trained model's parameters in a .pth file
d) run testModelTrack.py to test the accuracy of gesture detection by pressing 't' in real time. View that file for more info. 

# model.log is to provide graph of accuracy and loss during training
