{"cells":[{"cell_type":"markdown","metadata":{"id":"jq2dpaoW_M3g"},"source":["**Neural Network Tester and Trainer**"]},{"cell_type":"markdown","metadata":{"id":"RcRlzZgq26x8"},"source":["# Imports and Initializations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1649924857422,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"uojqT4COGdCO"},"outputs":[],"source":["\"\"\"\n","  This ipynb file is responsible to train your model. Please prepare a .npy file beforehand to train it.\n","  GrayScaled or RGB images are accepted.\n","\"\"\"\n","\n","import time\n","from tqdm import tqdm\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from matplotlib import style\n","from math import ceil\n","import torch.nn.functional as F\n","import os\n","from sys import path as sysPath\n","\n","# Set your CWD path to folder containing DL Model Architecture.\n","os.chdir(sysPath[0])\n","print(\"CWD: \", os.getcwd())\n","\n","# NETWORK ARCHITECTURE TO IMPORT [inside myModel folder following the example on top]\n","import COV_NET5 as NET_CLASS\n","import importlib\n","\n","# Reload Depp Learning model if there's any changes to its architecture\n","importlib.reload(NET_CLASS)\n","\n","print(\"GPU Avaialble:\", torch.cuda.device_count())\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","Net = NET_CLASS.Neural().to(device)\n","Net.showNetworkDetails()"]},{"cell_type":"markdown","metadata":{"id":"7Qj6iw43AYQ-"},"source":["# Prepare Training Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1649924857423,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"PSTyGLUf_GLl"},"outputs":[],"source":["import random\n","import cv2 as cv\n","\n","# initialize pseudo-random generator\n","random.seed()\n","\n","# == Training Data Section ==\n","\n","# set it to 3 dimension for RGB / BGR images\n","CHANNELS = 3\n","\n","GRAY = True # if you're training GRAYSCALED images, set True\n","\n","if GRAY:\n","  # set it to 1 dimension\n","  CHANNELS = 1\n","  \n","# IMAGE W/H and CLASSIFICATION LABELS\n","IMG_WIDTH = NET_CLASS.IMG_WIDTH\n","IMG_HEIGHT = NET_CLASS.IMG_HEIGHT\n","LABELS = NET_CLASS.CLASS_LABELS\n","\n","# Data augmentation to add. Currently only padding and rotation. [augment as much as you can]\n","data_transforms = transforms.Compose([\n","        transforms.Pad(random.randrange(10, 34, 2)),\n","        transforms.Resize((IMG_HEIGHT,IMG_WIDTH)),\n","        transforms.RandomRotation(degrees=[-15,+15])\n","])\n","\n","# TRAINING DATA TO IMPORT. EXP: training_data.npy\n","training_data = np.load(\"\", allow_pickle=True)\n","\n","# Shuffle and randomize the data loaded to encourage generalization and proper convergence.\n","np.random.shuffle(training_data)\n","\n","y_all = []\n","x_all = []\n","\n","for i in training_data:\n","        y_all.append(i[1].tolist())\n","y_all = torch.Tensor(np.array(y_all))\n","\n","\n","# === Create x_all training data for BGR ===\n","\n","if not GRAY:\n","\n","    for i in training_data:\n","        x_data = np.transpose(i[0],(2,0,1)) # (3, H, W)        \n","        x_all.append(x_data)\n","\n","    # convert to cuda float tensors\n","    x_all = torch.cuda.FloatTensor(x_all) \n","\n","    # augment data with 80% of being chosen\n","    for i in tqdm(range(len(x_all))):\n","        if random.random() < 0.8:\n","            x_all[i] = data_transforms(x_all[i])\n","\n","# === Create x_all training data for BGR ===\n","\n","\n","# === Create x_all training data for GRAYSCALED ===\n","\n","else:\n","    # convert data to torch.FloatTensor\n","    x_all = torch.Tensor([i[0] for i in training_data])\n","\n","    # augment data with 80% of being chosen\n","    for i in tqdm(range(len(x_all))):\n","        if random.random() < 0.8:\n","            x = x_all[i]\n","            \n","            x_all[i] = data_transforms(x.view(1, IMG_HEIGHT, IMG_WIDTH))\n","\n","# === Create x_all training data for GRAYSCALED ===\n","\n","\n","# Make all GRAYSCALED or BGR values range from 0-255 to 0-1 [normalize inputs]\n","x_all *= (1/255)\n","\n","# Separate loaded data into training and testing\n","VAL_PCT = 0.1\n","val_size = ceil(len(x_all)*VAL_PCT)\n","\n","train_X = x_all[:-val_size]\n","train_y = y_all[:-val_size]\n","\n","test_X = x_all[-val_size:]\n","test_y = y_all[-val_size:]\n","\n","print(\"total len:\", len(x_all))\n","print(\"train len:\", len(train_X))\n","print(\"test len:\", len(test_X))"]},{"cell_type":"markdown","metadata":{"id":"_jx6cT0w2h0A"},"source":["Show Training Data's Features"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1649924857423,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"i2zup4bfKsyx"},"outputs":[],"source":["# Show the shape of tensors loaded for confirmation\n","print(test_X[4].shape)\n","print(test_X[4].view(-1, CHANNELS, IMG_HEIGHT,IMG_WIDTH).shape)\n","print(test_X[4:8].shape)\n","print(test_X[4:8].view(-1, CHANNELS, IMG_HEIGHT, IMG_WIDTH).shape)\n","\n","# Get random test image\n","NUM = random.randint(0, len(test_X))\n","image = test_X[NUM]\n","\n","# Show images here\n","if not GRAY:\n","    # RGB IMG\n","    image = image.cpu().permute(1, 2, 0).numpy()[...,::-1].copy()\n","\n","    print(image.shape)\n","    print(\"Y:\", test_y[NUM])\n","    plt.imshow(image)\n","\n","else:\n","  # GRAY IMG\n","  print(image.shape)\n","  print(\"Y:\", test_y[NUM])\n","  plt.imshow(image, cmap=\"gray\")\n"]},{"cell_type":"markdown","metadata":{"id":"5sWEckLRBNnP"},"source":["# Training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1649924857424,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"a6P6urzmJ9dQ"},"outputs":[],"source":["# Choose optimizer to use\n","optimizer = optim.Adam(Net.parameters(), lr=0.00001)\n","# optimizer = optim.SGD(Net.parameters(), lr=0.001, momentum=0.8)\n","\n","# Choose loss function\n","loss_function = nn.MSELoss()\n","\n","\n","def fwd_pass(X,y,train=False):\n","    if not train:\n","        Net.zero_grad()\n","    \n","    outputs = Net(X)\n","\n","    matches = []\n","    matches = [torch.argmax(i)==torch.argmax(j) for i,j in zip(outputs, y)]\n","    acc = matches.count(True) / len(matches)    \n","    \n","    loss = loss_function(outputs, y)\n","    \n","    if train:\n","        loss.backward()\n","        optimizer.step()\n","    \n","    return acc, loss\n","\n","def test(size=32):\n","    \n","    random_start = np.random.randint(len(test_X)-size)\n","    X, y = test_X[random_start:random_start+size], test_y[random_start:random_start+size]\n","    \n","    with torch.no_grad():\n","        val_acc, val_loss = fwd_pass(X.view(-1, CHANNELS, IMG_HEIGHT,IMG_WIDTH).to(device), y.to(device))\n","    \n","    return val_acc, val_loss\n","\n","def trainModel():\n","    BATCH_SIZE = 16\n","    TEST_BATCH_SIZE = 32\n","    EPOCHS = 13\n","    \n","    with open(\"currentModelLog.log\", \"w\") as f:\n","        for epoch in range(EPOCHS):\n","            print(f\"EPOCH {epoch + 1}\", end=\": \")\n","            \n","            for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n","                batch_X = train_X[i:i+BATCH_SIZE].view(-1, CHANNELS, IMG_HEIGHT,IMG_WIDTH).to(device)\n","                batch_y = train_y[i:i+BATCH_SIZE].to(device)\n","                \n","                # Accuracy and loss for train images\n","                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n","                \n","                # for every 25 steps optimizer take, use test batches\n","                if i % 25 == 0:\n","\n","                    # Accuracy and loss from test images\n","                    val_acc, val_loss = test(TEST_BATCH_SIZE)\n","                    f.write(f\"{round(time.time(),3)}, { round(float(acc),2) }, {round(float(loss),2)}, {round(float(val_acc),2)}, {round(float(val_loss),2)}\\n\")\n","trainModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1649924857424,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"Mwkb5VEqUnyN"},"outputs":[],"source":["# Create graph to show training and testing's accuracy and loss values\n","style.use(\"ggplot\")\n","\n","def createGraph():\n","    contents = open(\"currentModelLog.log\", \"r\").read().split(\"\\n\")\n","    \n","    times = []\n","    accuracies = []\n","    losses = []\n","    \n","    val_accs = []\n","    val_losses = []\n","\n","    for c in contents:\n","        if c:\n","            timestamp, acc, loss, val_acc, val_loss = c.split(\",\")\n","            \n","            times.append(float(timestamp)) \n","            accuracies.append(float(acc)) \n","            losses.append(float(loss)) \n","            val_accs.append(float(val_acc)) \n","            val_losses.append(float(val_loss)) \n","    \n","    ax1 = plt.subplot2grid((2,1), (0,0))\n","    ax2 = plt.subplot2grid((2,1), (1,0))\n","    # ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n","    \n","    ax1.plot(times, accuracies, label=\"T Accuracy\")\n","    ax1.plot(times, val_accs, label=\"V Accuracy\")\n","    ax1.legend(loc=2)\n","    \n","    ax2.plot(times, losses, label=\"T Loss\")\n","    ax2.plot(times, val_losses, label=\"V Loss\")\n","    ax2.legend(loc=2)\n","    \n","    plt.show()\n","    \n","createGraph()\n"]},{"cell_type":"markdown","metadata":{"id":"meeOFZHA5k0V"},"source":["Save trained weights"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1649924857424,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"mejU6GAg5j3E"},"outputs":[],"source":["# provide directory and .pth file name to save trained weights.\n","torch.save(Net.state_dict(), \"\")"]},{"cell_type":"markdown","metadata":{},"source":["Test the trained weights of the model on a random image from test_X"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1649924857425,"user":{"displayName":"zadian zadia","userId":"15857602948862459199"},"user_tz":-480},"id":"hh8QWtBhZQhQ"},"outputs":[],"source":["TEST_NUM = random.randint(0, len(test_X))\n","\n","answer = -1\n","\n","prediction = Net(test_X[TEST_NUM].view(-1, CHANNELS, IMG_HEIGHT, IMG_WIDTH).to(device))[0]\n","\n","print(\"PREDICTION: \", prediction)\n","\n","for j in prediction:\n","    # if at least one prediction is above 10%\n","    if(j.item() > 0.1):\n","        \n","        answer = torch.argmax(prediction).item()\n","        prob = prediction[answer].item()\n","        break\n","\n","print(\"ANSWER INDEX:\", answer)\n","print(\"ANSWER PROBABILITY:\", prob)\n","\n","if answer < 0:\n","    print(\"ANSWER LABEL:\", \"UNKNOWN\")\n","else:\n","    print(\"ANSWER LABEL:\", LABELS[answer])\n","\n","image = test_X[TEST_NUM]\n","\n","print(\"PLT IMG SHAPE: \", image.shape)\n","\n","if not GRAY:\n","    # RGB IMG\n","    image = image.cpu().permute(1, 2, 0).numpy()[...,::-1].copy()\n","    plt.imshow(image)\n","\n","else:\n","    # GRAY IMG\n","    plt.imshow(image, cmap=\"gray\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Trainer to Upload.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
